Employees of a
credit bureau need to have access to customers' records so
that they can respond to reports of fraudulent transactions,
yet one may want to restrict the bureau's ability to compile
a list of customers' addresses and sell it to a third party.
An obfuscation algorithm is secure if any
access to the obfuscated database can be efficiently simulated
with access only to the ideal functionality.
The retriever processes the obfuscated database record by
record.
The algorithm is similar to the
one in section 4, and consists of generating a random secret
to encrypt each data attribute, splitting this secret into
(unequal) shares, and encrypting these shares under the keys
derived from the values of query attributes.
If Q contains this test, i.e., if Q contains X
j
=
108
x
j
for some candidate value x
j
(rather than X
j
= ),
then set (
s
i
1j
|| . . . || s
iN j
) = w
ij
prg
1,i,j
(H
2,i,j
(x
ij
)),
i.e., decrypt the secret bits with the key derived from
the value of the jth attribute.
C can thus be viewed as a monotone circuit over
the m + mN attribute equality predicates X
1
= x
1
, X
2
=
x
2
, . . . , X
m
= x
m
,
and X
j
= x
ij
for each i and j.
As a special case, if Ext can
recover the entire database D from I
D
, then the functionality
can be simulated, because the privacy policy is required
to be computable and the simulator is not required to be
computationally bounded (if we consider only privacy policies
which are computable in probabilistic polynomial time,
then we can define vacuousness with a PPT simulator as
well).
B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang.
