Can Machine Learning Be Secure?
ABSTRACT
Machine learning systems offer unparalled flexibility in dealing
with evolving input in a variety of applications, such as
intrusion detection systems and spam e-mail filtering. However
, machine learning algorithms themselves can be a target
of attack by a malicious adversary. This paper provides a
framework for answering the question, "Can machine learning
be secure?" Novel contributions of this paper include
a taxonomy of different types of attacks on machine learning
techniques and systems, a variety of defenses against
those attacks, a discussion of ideas that are important to
security for machine learning, an analytical model giving a
lower bound on attacker's work function, and a list of open
problems.
Categories and Subject Descriptors
D.4.6 [Security and Protection]: Invasive software (e.g.,
viruses, worms, Trojan horses); I.5.1 [Models]: Statistical;
I.5.2 [Design Methodology]

General Terms
Security

