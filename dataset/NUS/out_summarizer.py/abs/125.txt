The most commonly used dissimilarity
measure, namely the Euclidean metric, assumes that the dissimilarity
measure is isotropic and spatially invariant, and
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page.
The problem of finding non spherical
clusters is often addressed by utilizing a feature
weighting technique.
Diday et. al. [4] proposed the adaptive distance dynamic
clusters (ADDC) algorithm in this vain.
While
this restricts the dissimilarity measures to have axis parallel
isometry, the weights also provide a simple interpretation of
the clusters in terms of relevant features, which is important
in knowledge discovery.
These two algorithms are explained in Appendix A.
Finally, we summarize our contributions and conclude with
some future directions in Section 5.
To avoid
the trivial solution to J (W, C), we consider a normalization
condition on w
j
, viz.,
M
l=1
w
jl
= 1.
(7)
Note that even with this condition, J (W, C) has a trivial
solution: w
jp
= 1 where p = arg min
l
x
i
R
j
g
l
(x
i
, c
j
),
and the remaining weights are zero.
APPENDIX
A.
OTHER FEATURE WEIGHTING
CLUSTERING TECHNIQUES
A.1
Diagonal Gustafson Kessel (DGK)
Gustafson and Kessel [7] associate each cluster with a different
norm matrix.
In [5], a heuristic is used to estimate the
value
j
in every iteration and set the negative values of w
jl
to zero before normalizing the weights.
