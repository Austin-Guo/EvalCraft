For example, we may wish to partition a set of web logs to infer certain usage patterns, or divide a corpus of documents into a small number of related groups.
We also restrict our attention to the metric version of the problems throughout this paper; the given distance matrix defines a metric space over the set of input points, that is, the distances are nonnegative, symmetric, satisfy the triangle inequality, and the distance between points x and y is zero if and only if y.
We note that even for moderate weights, say O(n 2 ), the naive approach of viewing a weighted point as a collection of unit-weight points increases the input size dramatically.
Our algorithm begins by partitioning the points into r w power-of-2 weight classes and applying the uniform-weights algorithm within each weight class (i.e., we ignore the differences between weights belonging to the same weight class, which are less than a factor of 2 apart).
Addition- ally, the algorithms of Indyk and Thorup both succeed with a constant probability, while our sampling algorithm is guaranteed to succeed with high probability.
Then cost (X) is at least cost (i r 0it 0it 0it 0it where the first step follows from Lemma 2.8, the second step follows from averaging and the choice of j, the third step follows from Lemma 2.10, the fourth step follows from Lemma 2.7, and the last step follows since C i  U .
We then obtain a (k, O(1))-configuration by creating a problem instance from the (O(krw ), O(1))-configuration computed in the previous step and then feeding this problem instance as input to an O(1)-approximate k-median algorithm.
We now observe that the above algorithm corresponds to the special case of algorithm Small- Space of [5] in which the parameter ' is set to r w , the uniform weights algorithm of Section 3 is used in step 2 of Small-Space, and the online median algorithm of [10] is used in step 4 of Small- Space.
