This motivates some of our models where the on-line player knows the order of the target probabilities, but not their numerical values.
Once we have dened the competitive ratio of a strategy for every chance node, we just take the maximum as the \overall" competitive ratio of the strategy, since the adversary has the free choice among the chance nodes.
In order to get in easier, we will rst consider simple models where the jobs have target probabilities turn out that the main results carry over to the Bayesian model and to the AIRS setting where the on-line player gets a random signal correlated to the adversarial target.
Recall the signal density function e s t for s  t, and 0 for s > t. For the sake of simplicity we will not distinguish signals between the same consecutive targets candidates, that is, we only use n signals corresponding to the n 1 intervals between objects (genes) together with the innite leftmost interval.
This can lead to dierent schedules depending on which expected value one wishes to optimize: ER measures the time wasted on false candidates relative to the target decision time, whereas RE is proportional to the expected target completion time.
One may claim that Q plays a similar role in our search problem as e.g. the Shannon entropy in searching by comparisons, so far as it measures the expected amount of work needed to nd an item under a given probability distribution.
By Theorem 4.3 and Lemma 4.4 we have ER =n lack knowledge of the signal probabilities but still know that, for any s i , the likelihood p(s i jt j ) decreases as j grows, we may apply Harmonic to the target candidates to the right of the actual signal.
Theorem 5.1 IRR gives the optimal competitive ratio for every interval system [a against an adversary who can choose both the target and the decision times within the given intervals.
