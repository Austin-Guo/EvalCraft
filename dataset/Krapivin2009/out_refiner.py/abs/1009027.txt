Information drawn from the corpus as a whole generally consists of aggregates of statistics gathered from each document considered in isolation; for example, the inverse document frequency is based on checking, for each docu- ment, whether that document contains a particular term.
For example, we could infer that a document not containing a certain query term is still relevant if the document belongs to a cluster whose component documents generally do contain the term.
While one could compute clusters specic to q at retrieval time, eciency considerations compel us to create Clusters(C), the We include soft or probabilistic clusters in this category.
Interestingly, Hofmann [8] linearly interpolated his probabilistic model's score, which is based on (soft) clusters, with the usual cosine metric; this is quite close in spirit to what our interpolation algorithm does.
While one of our goals is to demonstrate that incorporating corpus structure as in our retrieval framework can provide improvements over the performance of the standard LM algorithm, we also wish to detemine whether our algorithms are competitive with state-of-the-art language-modeling-based algorithms.
For our novel algorithms, we optimized the cluster-size parameter k and the interpolation algorithm's interpolation parameter , but the other parameters were set to default values suggested in the previous literature [19]; thus, the baseline algorithm was given an extra advantage.
Finally, the generally high performance of our aspect-x and interpolation algorithms seems to support our claims as to the importance of using corpus-structural information in the particular ways we have suggested: specically, in these two algorithms, clusters play both a selection and a smoothing role, and both document-specic information and intra-cluster structure are incorporated as well.
Note that this version of the basis- select algorithm corresponds to applying the basic LM approach to the \document" Cohort(d) rather than d itself, and so can be thought of as a smoothing method wherein the document language model is created by backing completely to a cluster language model.
