Along the first dimension, one can distinguish between GKE protocols that assume an authentic network (as we do) [19, 8, 26, 24, 27], and GKE protocols that rely on a-priori distributed public and private keys (as for example provided by a public-key recent paper of Katz and Yung [21] closes the bridge between these two approaches by showing how any GKE protocol built for an authentic network can be "compiled" into a GKE protocol for an insecure net-work with a-priori distributed public and private keys.
In case that the GCS detects nested leaves, i.e., detects leaving servers during the execution of a (dynamic) GKE protocol, this protocol is aborted and a basic GKE protocol is run from scratch among the remaining servers.
If a hybrid system Sys hybrid; g n consisting of a real system Sys real; n with sub-system Sys ideal;g n is as secure as an ideal system Sys ideal;f n , and if a real system Sys real; n is as secure as the ideal system Sys ideal;g then the real system Sys real; n consisting of Sys real; n with sub-system Sys real; n is at least as secure the ideal system Sys ideal;f n . Complexity Measures.
Recall that our goal is to build a GKE protocol  that is not only secure, but also guarantees to terminate for every server even if up to tc servers crash.
By the assumption that at most tc servers crash, it follows that every server in U receives n tc contribution values y j and proposes some values for ID jcs.
In the first stage, it chooses an arbitrary set M of n tc servers, and runs the protocol in an arbitrary way, but ensuring that: all messages sent among servers in M are delivered, no message is delivered which is either sent by or sent to a server not in M , and no server is crashed or broken into.
In protocol !, a server i continues to participate in the protocol after outputting the session key sk .
When server j receives server i's public key p i , it chooses a random vector r ij over , encrypts it (component-wise) under p i to get ij , and sends c ij to server i.
