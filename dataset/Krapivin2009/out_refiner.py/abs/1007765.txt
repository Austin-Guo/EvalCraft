This problem formulation is motivated in part by some clustering problems at Whizbang Labs in which learning algorithms have been trained to help with various clustering tasks [8, 9, 10].
To get a feel for this problem, notice that if there exists a perfect clustering, i.e., one that gets all the edges correct, then the optimal clustering is easy to find: just delete edges and output the connected components of the graph remaining.
Given a clustering of V in which all clusters are -clean for some -  1=4, then the number of mistakes made by this clustering is at most 8mOPT .
Proof: Let the clustering on V be bound the number of mistakes made by this clustering by 8 times the number of edge-disjoint "erroneous triangles" in the graph, where an erroneous triangle is a triangle having two edges and one edge.
We get the following result  Theorem 11 The General Partitioning algorithm returns a clustering of graph G which has more than OPT agreements with probability at least 1 -.
We begin by defining a measure of goodness of a clustering of some set U i with respect to fW i g, that will enable us to pick the right clustering of the set U i . satisfies the following for all and, for at least (1  0 )n of the vertices x and 8 j, Our algorithm is as follows: Algorithm Divide&Choose: 1. Pick a random subset W  V of size m.
The algorithm can fail in four situations: more than =2 do not have an  0 -good partition with probability at most =2, lemma 13 does not hold for some W i with probability at most 2ke  02 m=2 , lemma 15 does not hold for some i with probability at most 8k m=4 or lemma 14 does not hold for some pair with probability at most .
So, consider clustering greedily: pick an arbitrary node v, produce a cluster then repeat on probability we will correctly cluster all nodes whose clusters in OPT are of size !(log n).
