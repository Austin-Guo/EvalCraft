We provide a framework for the analysis of the trade off between static caching of query answers and posting lists; • Static caching of terms can be more effective than dynamic caching with, for example, LRU.
We provide algorithms based on the Knapsack problem for selecting the posting lists to put in a static cache, and we show improvements over previous work, achieving a hit ratio over 90%; • Changes of the query distribution over time have little impact on static caching.
Buckley and Lewit [3], in one of the earliest works, take a term at a time approach to deciding when inverted lists need not be further examined.
Based on the observations of Markatos, Lempel and Moran propose a new caching policy, called Probabilistic Driven Caching, by attempting to estimate the probability distribution of all possible queries submitted to a search engine [8].
It is possible that queries that are most frequent after the cache have different characteristics, and tuning the search engine to queries frequent before the cache may degrade performance for non cached queries.
For the dynamic algorithms, we load the cache with terms in order of fq(t) and we let the cache warm up for 1 million queries.
To estimate the time interval in which we need to recompute the posting lists on the static cache we need to consider an efficiency/quality trade off: using too short a time interval might be prohibitively expensive, while recomputing the cache too infrequently might lead to having an obsolete cache not corresponding to the statistical characteristics of the current query stream.
We also propose a new algorithm for static caching of posting lists that outperforms previous static caching algorithms as well as dynamic algorithms such as LRU and LFU, obtaining hit rate values that are over 10% higher compared these strategies.
