Interesting Nuggets and Their Impact on Definitional Question Answering Kian Wei Kor Department of Computer Science School of Computing National University of Singapore dkor@comp.nus.edu.sg Tat Seng Chua Department of Computer Science School of Computing National University of Singapore chuats@comp.nus.edu.sg  H.3.3 [Information Search and Retrieval]: Retrieval Models; H.1.2 [User/Machine Systems]: Human Factors General Terms Algorithms, Human Factors, Experimentation 1. DEFINITIONAL QUESTION ANSWERING Definitional Question Answering was first introduced to the TExt Retrieval Conference Question Answering Track main task in 2003.
As an African American professional heavyweight boxer, an average human reader would find the last three nuggets about George Foreman interesting because boxers do not usually lend their names to food preparation products, nor do boxers retire for 10 years before returning to the ring and become the world"s oldest boxing champion.
However if individual sentences are viewed as a document, then relevance based approaches essentially use the collected topic specific centroid words as a form of document retrieval with automated query expansion to identify strongly relevant sentences.
Since sentences in the Interest Corpus of articles we collected from the internet are likely to contain nuggets that are of interest to human readers, we can essentially use each sentence as pseudocentroids.
We compare the results attained by the Human Interest Model that only identify interesting nuggets with the results of the syntactic pattern finding Soft Pattern model as well as the result of the top performing definitional system in TREC 2005 [13].
Informative nuggets present a general overview of the topic while interesting nuggets give readers added depth and insight by providing novel and unique aspects about the topic.
To verify if both systems are selecting the same answer nuggets, we randomly selected a subset of 10 topics from the TREC 2005 question set and manually identified correct answer nuggets (as defined by TREC accessors) from both systems.
We suspect the main contributor to the system"s performance Entity Type Topics ORGANIZATION DePauw University, Merck & Co., Norwegian Cruise Lines (NCL), United Parcel Service (UPS), Little League Baseball, Cliffs Notes, American Legion, Sony Pictures Entertainment (SPE), Telefonica of Spain, Lions Club International, AMWAY, McDonald"s Corporation, Harley Davidson, U.S. Naval Academy, OPEC, NATO, International Bureau of Universal Postal Union (UPU), Organization of Islamic Conference (OIC), PBGC PERSON Bing Crosby, George Foreman, Akira Kurosawa, Sani Abacha, Enrico Fermi, Arnold Palmer, Woody Guthrie, Sammy Sosa, Michael Weiss, Paul Newman, Jesse Ventura, Rose Crumb, Rachel Carson, Paul Revere, Vicente Fox, Rocky Marciano, Enrico Caruso, Pope Pius XII, Kim Jong Il THING F16, Bollywood, Viagra, Howdy Doody Show, Louvre Museum, meteorites, Virginia wine, Counting Crows, Boston Big Dig, Chunnel, Longwood Gardens, Camp David, kudzu, U.S. Medal of Honor, tsunami, genome, Food for Oil Agreement, Shiite, Kinmen Island EVENT Russian submarine Kursk sinks, Miss Universe 2000 crowned, Port Arthur Massacre, France wins World Cup in soccer, Plane clips cable wires in Italian resort, Kip Kinkel school shooting, Crash of EgyptAir Flight 990, Preakness 1998, first 2000 Bush Gore presidential debate , 1998 indictment and trial of Susan McDougal, return of Hong Kong to Chinese sovereignty, 1998 Nagano Olympic Games, Super Bowl XXXIV, 1999 North American International Auto Show, 1980 Mount St. Helens eruption, 1998 Baseball World Series, Hindenburg disaster, Hurricane Mitch Table 3: TREC 2005 Topics Grouped by Entity Type is Google"s PageRank algorithm, which mainly consider the number of linkages, has an indirect effect of ranking web documents by the degree of human interest.
