State of the art information retrieval systems commonly use machine learning techniques to learn ranking functions.
Given a learned weight vector w, predicting a ranking (i.e. solving equation (1)) given query x reduces to picking each yij to maximize wT Ψ(x, y).
In other words, the algorithm maximizes H for each non relevant document, d¯x j , Algorithm 2 Finding the Most Violated Constraint (argmax H) for Algorithm 1 with ∆map 1: Input: w, Cx , C¯x 2: sort Cx and C¯x in descending order of wT φ(x, d) 3: sx i ← wT φ(x, dx i ), i = 1, . . . , |Cx | 4: s¯x i ← wT φ(x, d¯x i ), i = 1, . . . , |C¯x | 5: for j = 1, . . . , |C¯x | do 6: optj ← argmaxk δj(k, |Cx | + 1) 7: end for 8: encode ˆy according to (7) 9: return ˆy without considering the positions of the other non relevant documents, and thus ignores the constraints of (9).
For example, for document d, query q and retrieval function f, if the score f(d|q) is in the top 90% of the scores f(·|q) for query q, then the converted score is f (d|q) = 0.9.
B. T. Bartell, G. W. Cottrell, and R. K. Belew.
C. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender.
C. J. C. Burges, R. Ragno, and Q. Le. Learning to rank with non smooth cost functions.
Adapting ranking SVM to document retrieval.
