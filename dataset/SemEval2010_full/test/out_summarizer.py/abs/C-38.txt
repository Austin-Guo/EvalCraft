Limited deployment of IP multicast has motivated a new distribution paradigm over the Internet based on overlay networks where a group of participating end systems (or peers) form an overlay structure and actively participate in distribution of content without any special support from the network (e.g., [7]).
Constructing a peer to peer overlay for streaming applications should not only accommodate global design goals such as scalability and resilience but also satisfy the local design goal of maximizing delivered quality to individual peers 1 . More specifically, delivered quality of streaming content to each peer should be proportional to its incoming access link bandwidth.
We conclude that a practical solution for peer topeer streaming applications should incorporate the following design properties: (i) it should use an unstructured, multiparent peer to peer overlay, (ii) it should provide a scalable peer discovery mechanism that enables each peer to find its good parents efficiently, (iii) it should detect (and possibly avoid) any shared bottleneck among different connections in the overlay, and (iv) it should deploy congestion controlled connections but ensure in time arrival of delivered segments to each receiver.
No of active parents for pi at time t img sz Size of local image at each peer sgm Size of gossip message delij Estimated delay between pi and pj Clearly, properties of the selected utility function as well as accuracy of estimated parameters (in particular using outgoing bandwidth instead of available bandwidth) determine properties of the local image at each peer which in turn affects performance of the framework in some scenarios.
The gossip mechanism works as follow: each peer maintains a local image that contains up to img sz records where each record represents the following information for a previously discovered peer pi in the overlay: 1) IP address, 2) GNP coordinates, 3) number of received layers, 4) timestamp when the record was last generated by a peer, 5) outbwi and 6) inbwi.
Image maintenance mechanism evicts extra records (beyond img sz) that satisfy one of the following conditions: (i) represent peers with the lower utility, (ii) represent peers that were already dropped by the PS mechanism due to poor performance and (iii) have a timestamp older than a threshold.
To avoid selecting a poorly performing parent in the near future, the receiver associates a timer to each parent and exponentially backs off the timer after each failed experience [13].
Given the available bandwidth from all parents (including the new one) and possible correlation among them, a receiver can use one of the following criteria to drop a parent: (i) to maximize the bandwidth, the receiver can drop the parent that contributes minimum bandwidth, (ii) to maximize path diversity among connections from parents, the receiver should drop the parent that is located behind the same bottleneck with the largest number of active parents and contributes minimum bandwidth among them.
