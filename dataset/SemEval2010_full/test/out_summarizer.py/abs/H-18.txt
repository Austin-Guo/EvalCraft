At a finer granularity, users may actually be looking to obtain sections of a document similar to a particular section that presumably discusses a topic of the users interest.
Obviously, our approach can handle single documents as a special case when multiple documents are unavailable.
Sd into p segments sequentially (some segments may be empty), and put them into the p segments ˆS of the whole training set D (all possible cases of different segmentation Segd and alignment Alid are checked) to find the optimal case, and (2) based on the current segmentation and alignment, for each term t, the algorithm finds the best term cluster of t based on the current segmentation Segd and alignment Alid.
The criterion of evaluation is just using the proportion of the number of sentences with wrong predicted segment labels in the total number of sentences in the whole training Table 4: Average Error Rates of Multi document Segmentation Given Segment Numbers Known #Doc MIl WMIl k MIk WMIk 102 3.14% 2.78% 300 4.68% 6.58% 51 4.17% 3.63% 300 17.83% 22.84% 34 5.06% 4.12% 300 18.75% 20.95% 20 7.08% 5.42% 250 20.40% 21.83% 10 10.38% 7.89% 250 21.42% 21.91% 5 15.77% 11.64% 250 21.89% 22.59% 2 25.90% 23.18% 50 25.44% 25.49% 1 23.90% 24.82% 25 25.75% 26.15% Table 5: Multi document Segmentation: P values of T test on Error Rates for MIl and WMIl #Doc 51 34 20 10 5 2 P value 0.19 0.101 0.025 0.001 0.000 0.002 set as the error rate: p(error|predicted, real) = d∈D s∈Sd 1(predicteds=reals)/ d∈D nd.
Second, as noted at the beginning of this section, if two documents have more document dependent stop words or noisy words than cue words, then the algorithm may view them as two different segments and the other segment is missing.
When the document number is not large (about from 2 to 10), all the cases using term weights have better performances than MIl : a = 0, b = 0 without term weights, but when the document number becomes larger, the cases WMIl : a = 1, b = 0 and WMIl : a = 2, b = 1 become worse than MIl : a = 0, b = 0.
However, usually cue terms or sentences appear at the beginning of a segment, while the end of the segment may be 1 2 5 10 20 34 51 102 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Document Number ErrorRate MIl :a=0,b=0 WMI l :a=1,b=1 WMI l :a=1,b=0 WMI l :a=2,b=1 Figure 3: Error rates for different hyper parameters of term weights.
H. Zha and X. Ji. Correlating multilingual documents via bipartite graph modeling.
